{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**NOME: Diego Batalha** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Recuperação de Informações\n",
    "\n",
    "## Lista 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1:\n",
    "A partir de um corpus à sua escolha, estime um modelo de assuntos baseado no Modelo LSI. Uma vez calculado o modelo, defina um conjunto de **documentos relevantes (${\\cal R}$)** para um assunto, como os $n$ documentos que contiverem em sua representação LSI, os maiores coeficientes para o assunto escolhido. Construa uma consulta $q$, com as dez palavras mais importantes do assunto escolhido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import machado\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Definindo um tema para análise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos = [machado.raw(id) for id in machado.fileids()]\n",
    "swu = stopwords.words('portuguese') + list (string.punctuation)\n",
    "stemmer = PortugueseStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos_limpos = []\n",
    "for texto in textos:\n",
    "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos_limpos.append(tlimpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(textos_limpos)\n",
    "corpus = [dictionary.doc2bow(text) for text in textos_limpos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = mod_tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=200)\n",
    "corpus_lsi = mod_lsi[corpus_tfidf] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cecíl', -0.56734219735658364),\n",
       " ('luís', 0.4283021670907971),\n",
       " ('alves', 0.20137512502482369),\n",
       " ('venânci', -0.13207811179098244),\n",
       " ('carlot', -0.1232977976792473),\n",
       " ('major', 0.11894631801782865),\n",
       " ('magalhã', -0.11637546023257263),\n",
       " ('albert', 0.11481660552969568),\n",
       " ('tibúrci', -0.10886793623477559),\n",
       " ('marcelin', 0.10287118355012102)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topico = 5\n",
    "mod_lsi.show_topic(topico,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i,texto in enumerate(corpus_lsi):\n",
    "    lista.append((texto[topico][1],i))\n",
    "\n",
    "R_relevantes = []\n",
    "n_relevantes = 25\n",
    "for i in sorted(lista,reverse = True)[:n_relevantes]:\n",
    "    R_relevantes.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{261, 265, 270, 15, 287, 416, 289, 288, 163, 38, 299, 45, 55, 441, 64, 456, 81, 82, 83, 93, 221, 481, 369, 244, 251}\n"
     ]
    }
   ],
   "source": [
    "R_relevantes = set(R_relevantes)\n",
    "print(R_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_relevantes = 10\n",
    "q_consulta = []\n",
    "for t in mod_lsi.show_topic(topico,10):\n",
    "    q_consulta.append(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cecíl', 'luís', 'alves', 'venânci', 'carlot', 'major', 'magalhã', 'albert', 'tibúrci', 'marcelin']\n"
     ]
    }
   ],
   "source": [
    "print(q_consulta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicionario' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ee882b5213bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicionario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;36m498\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5886\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicionario' is not defined"
     ]
    }
   ],
   "source": [
    "print(dicionario)\n",
    "print(corpus)\n",
    "498*5886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicionario' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-58267b0e2e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicionario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicionario' is not defined"
     ]
    }
   ],
   "source": [
    "print(dicionario[0])\n",
    "for doc in corpus[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: \n",
    "Reutilizando os índices invertidos construídos em exercícios anteriores(Booleano, e TFIDF), calcule a precisão e revocação  com a consulta $q$ e o conjunto relevante ${\\cal R}$ definidos no exercício anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indice = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos_limpos):\n",
    "    for term in t:\n",
    "        indice[term].add(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_adv(search, indice):\n",
    "\n",
    "    resultado = indice[search[0]]\n",
    "    for token in search[1:]:\n",
    "            resultado = resultado | indice[token]\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 4, 5, 11, 12, 13, 15, 16, 18, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 36, 38, 39, 40, 43, 45, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 64, 66, 67, 71, 76, 80, 81, 82, 83, 84, 92, 93, 95, 96, 105, 107, 110, 113, 120, 121, 122, 128, 139, 140, 151, 154, 158, 161, 162, 163, 165, 168, 171, 174, 175, 176, 179, 182, 183, 185, 187, 188, 190, 191, 192, 193, 205, 206, 207, 208, 210, 211, 217, 218, 219, 221, 222, 224, 227, 229, 230, 231, 232, 233, 234, 235, 239, 240, 242, 244, 245, 246, 249, 251, 254, 255, 256, 257, 258, 260, 261, 263, 265, 266, 267, 269, 270, 272, 273, 277, 282, 286, 287, 288, 289, 290, 298, 299, 301, 302, 311, 313, 316, 319, 326, 327, 328, 334, 345, 346, 357, 360, 364, 367, 368, 369, 371, 374, 377, 380, 381, 382, 385, 388, 389, 391, 393, 394, 396, 397, 398, 399, 411, 416, 423, 424, 425, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 441, 442, 443, 444, 446, 447, 448, 450, 451, 456, 463, 464, 465, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 481, 482, 483, 484, 486, 487, 488, 490, 491}\n"
     ]
    }
   ],
   "source": [
    "resp_boo = busca_adv(q_consulta,indice)\n",
    "resp_boo = set(resp_boo)\n",
    "print(resp_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = nltk.TextCollection(textos_limpos)\n",
    "\n",
    "tfidf_matrix = np.zeros((len(textos_limpos),len(q_consulta)))\n",
    "\n",
    "for j, termo in enumerate(q_consulta):\n",
    "    for i, texto in enumerate(textos_limpos):\n",
    "        tfidf_matrix[i,j] = T.tf_idf(termo,texto)\n",
    "        \n",
    "Mtfidf_Norm = np.array([r/norm(r) if norm(r) !=0 else np.zeros(len(r)) for r in tfidf_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ordem(q,MN):\n",
    "    return [np.dot(q,r) for r in MN]\n",
    "\n",
    "vetor_tfidf = np.array([T.tf_idf(w,q_consulta) for w in q_consulta])\n",
    "vetor_tfidf /= norm(vetor_tfidf)\n",
    "resp_tfidf = ordem(vetor_tfidf,Mtfidf_Norm)\n",
    "\n",
    "vtfidf = filter(lambda x : x[0]!=0.0, zip(resp_tfidf,range(len(textos_limpos))))\n",
    "\n",
    "temp_tfidf = sorted(vtfidf, reverse=True)\n",
    "\n",
    "trunc = 0.3\n",
    "resp_tfidf = []\n",
    "for i in temp_tfidf:\n",
    "    if i[0]>= trunc:\n",
    "        resp_tfidf.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 258, 2, 388, 389, 263, 391, 393, 11, 140, 397, 13, 399, 139, 15, 273, 272, 26, 158, 288, 161, 33, 34, 165, 38, 423, 168, 425, 299, 301, 430, 431, 48, 429, 52, 182, 183, 57, 442, 185, 443, 187, 441, 191, 447, 193, 66, 67, 326, 328, 206, 463, 208, 465, 82, 469, 470, 471, 217, 346, 219, 345, 93, 221, 95, 481, 482, 483, 487, 232, 364, 367, 239, 240, 371, 244, 374, 120, 122, 254}\n"
     ]
    }
   ],
   "source": [
    "resp_tfidf = set(resp_tfidf)\n",
    "print(resp_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RevPre(parcial,geral):\n",
    "    \n",
    "    #parcial = 'documentos encontrados'\n",
    "    #geral = 'documentos relevantes'\n",
    "    \n",
    "    rev = len(parcial & geral)/len(geral)\n",
    "    pre = len(parcial & geral)/len(parcial)\n",
    "    \n",
    "    print('Revocação = ' + str(rev))\n",
    "    print('Precisão = ' + str(pre))\n",
    "    \n",
    "    #return rev,pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para a busca booleana\n",
      "Revocação = 1.0\n",
      "Precisão = 0.11363636363636363\n",
      "\n",
      "\n",
      "Resultados para a busca por tf_idf\n",
      "Revocação = 0.4\n",
      "Precisão = 0.125\n"
     ]
    }
   ],
   "source": [
    "print('Resultados para a busca booleana')\n",
    "RevPre(resp_boo,R_relevantes)\n",
    "print('\\n')\n",
    "print('Resultados para a busca por tf_idf')\n",
    "RevPre(resp_tfidf,R_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: \n",
    "Usando as definições de probabilidade de relevância apresentadas no capítulo 11 do Livro, construa uma função de recuperação probabilística usando o *log da razão de Odds* como **RSV** (retrieval status value). Calcule revocação e precisão para consulta $q$ e conjunto relevante ${\\cal R}$. Compare a probabilidade $p_t=P(x_t=1|R=1,q)$, com a o rankeamento de importância das palavras que compõem o assunto escolhido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_busca(query, indice, relevantes, N_docs = 246):\n",
    "    \n",
    "    #query = consulta a ser realizada\n",
    "    #indice = indice invertido\n",
    "    #relevantes = conjunto de documentos atualmente considerados relevantes\n",
    "    #N_docs = número de documentos presente no corpus\n",
    "    \n",
    "    query_tok = query #[stemmer.stem(token.lower())  for token in WordPunctTokenizer().tokenize(query) if token not in swu]\n",
    "    \n",
    "    ct = []\n",
    "    S = len(relevantes)\n",
    "    N = N_docs\n",
    "    \n",
    "    for termo in query_tok:\n",
    "        s = len(indice[termo] & relevantes)\n",
    "        df = len(indice[termo])\n",
    "        \n",
    "        up = s/(S - s +0.5)\n",
    "        down =(df - s)/(N - df - S + s -0.5)\n",
    "        \n",
    "        ct.append(np.log(up/down))\n",
    "    \n",
    "    RSVs = []\n",
    "    for doc in range(N):\n",
    "        rsv = 0\n",
    "        for pos,termo in enumerate(query_tok):\n",
    "            if doc in indice[termo]:\n",
    "                rsv += ct[pos]\n",
    "        RSVs.append((rsv,doc))\n",
    "        \n",
    "    resultado = sorted(RSVs,reverse=True)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4.6817989334694596, 57), (4.3926449489384423, 82), (4.0787876747445351, 219), (4.0787876747445351, 13), (4.0584755342905527, 93), (3.4385386159004221, 207), (3.4385386159004221, 1), (3.4182264754464398, 221), (3.4182264754464398, 15), (3.0840570607985502, 244)]\n"
     ]
    }
   ],
   "source": [
    "temp_prob = prob_busca(q_consulta,indice,R_relevantes)\n",
    "print(temp_prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 4, 12, 13, 15, 21, 23, 27, 28, 158, 34, 163, 36, 38, 39, 45, 176, 49, 51, 182, 57, 59, 188, 61, 192, 64, 205, 206, 207, 81, 82, 210, 83, 218, 219, 92, 221, 93, 96, 227, 229, 233, 234, 240, 113, 242, 244, 245, 122}\n"
     ]
    }
   ],
   "source": [
    "trunc = 1\n",
    "resp_prob = []\n",
    "for i in temp_prob:\n",
    "    if i[0] >= trunc:\n",
    "        resp_prob.append(i[1])\n",
    "        \n",
    "resp_prob = set(resp_prob)\n",
    "print(resp_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revocação = 0.44\n",
      "Precisão = 0.22\n"
     ]
    }
   ],
   "source": [
    "RevPre(resp_prob,R_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_termo = []\n",
    "S = len(R_relevantes)\n",
    "for termo in q_consulta:\n",
    "    s = len(indice[termo] & R_relevantes)\n",
    "    p_termo.append((termo,s/S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cecíl', 0.0), ('luís', 0.92), ('alves', 0.16), ('venânci', 0.0), ('carlot', 0.16), ('major', 0.28), ('magalhã', 0.0), ('albert', 0.16), ('tibúrci', 0.08), ('marcelin', 0.16)]\n",
      "\n",
      "\n",
      "[('cecíl', -0.56734219735658364), ('luís', 0.4283021670907971), ('alves', 0.20137512502482369), ('venânci', -0.13207811179098244), ('carlot', -0.1232977976792473), ('major', 0.11894631801782865), ('magalhã', -0.11637546023257263), ('albert', 0.11481660552969568), ('tibúrci', -0.10886793623477559), ('marcelin', 0.10287118355012102)]\n"
     ]
    }
   ],
   "source": [
    "print(p_termo)\n",
    "print('\\n')\n",
    "print(mod_lsi.show_topic(topico,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4:\n",
    "Repita o exercício 3 agora usando o modelo **Okapi BM25** para o rankeamento. Calcule precisão e revocação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def okapi_busca(query, indice, corpo):\n",
    "    \n",
    "    #query = consulta a ser realizada\n",
    "    #indice = indice invertido\n",
    "    #corpo = corpus\n",
    "    \n",
    "    query_tok = query #[stemmer.stem(token.lower())  for token in WordPunctTokenizer().tokenize(query) if token not in swu]\n",
    "    \n",
    "    N = len(corpo)\n",
    "    \n",
    "    L = []\n",
    "    for texto in corpo:\n",
    "        L.append(len(texto))\n",
    "        \n",
    "    L_ave = sum(L)/N\n",
    "    k1 = 1.2\n",
    "    b = 0.75\n",
    "    \n",
    "    RSVs = []\n",
    "    for doc in range(N):\n",
    "        rsv = 0\n",
    "        \n",
    "        for termo in query_tok:\n",
    "            if doc in indice[termo]:\n",
    "                tf = 1 #pode ser alterado para melhor representar a frequencia\n",
    "            df = len(indice[termo])\n",
    "        rsv += np.log(N/df)*((k1 + 1)*tf)/(k1*(1 - b + (b*(L[doc]/L_ave))) + tf)\n",
    "        \n",
    "        RSVs.append((rsv,doc))\n",
    "        \n",
    "    resultado = sorted(RSVs,reverse=True)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6.2393542810351423, 405), (6.2393542810351423, 199), (6.2027710326330876, 457), (6.2027710326330876, 417), (6.2007879168888991, 410), (6.2007879168888991, 204), (6.1522693329462017, 403), (6.1522693329462017, 197), (6.1490184201635358, 376), (6.1490184201635358, 170)]\n"
     ]
    }
   ],
   "source": [
    "temp_okapi = okapi_busca(q_consulta,indice, textos_limpos)\n",
    "print(temp_okapi[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 4, 12, 13, 15, 21, 23, 27, 28, 158, 34, 163, 36, 38, 39, 45, 176, 49, 51, 182, 57, 59, 188, 61, 192, 64, 205, 206, 207, 81, 82, 210, 83, 218, 219, 92, 221, 93, 96, 227, 229, 233, 234, 240, 113, 242, 244, 245, 122}\n"
     ]
    }
   ],
   "source": [
    "trunc_okapi = 1\n",
    "resp_okapi = []\n",
    "for i in temp_okapi:\n",
    "    if i[0] >= trunc_okapi:\n",
    "        resp_okapi.append(i[1])\n",
    "        \n",
    "resp_okapi = set(resp_okapi)\n",
    "print(resp_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revocação = 1.0\n",
      "Precisão = 0.05122950819672131\n"
     ]
    }
   ],
   "source": [
    "RevPre(resp_okapi,R_relevantes)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
